{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show labels\n",
    "labels = idx2numpy.convert_from_file('../data/train-labels-idx1-ubyte')\n",
    "torch.tensor(np.array(labels, copy=True)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data():\n",
    "    # read test data\n",
    "    t10k = idx2numpy.convert_from_file('../data/t10k-images-idx3-ubyte')\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # transform test datasets\n",
    "    new_test = []\n",
    "    for x in t10k:\n",
    "        new_test.append(transform_test(Image.fromarray(np.uint8(x))))\n",
    "\n",
    "    # convert to tensor of proper size\n",
    "    test_tensor = torch.Tensor(len(new_test), 28, 28)\n",
    "    torch.cat(new_test, out=test_tensor)\n",
    "    new_test = test_tensor.view(-1, 1, 28, 28)\n",
    "    \n",
    "    # create dataset\n",
    "    test_data = TensorDataset(new_test)\n",
    "\n",
    "    # create data loader\n",
    "    batch_size = 1\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return test_loader\n",
    "\n",
    "test_loader = prepare_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        # linear layers\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        # max pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flattening the image\n",
    "        x = x.view(-1, 7 * 7 * 16)\n",
    "        # linear layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('../trained_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "output = []\n",
    "\n",
    "for batch_idx, (data,) in enumerate(test_loader):\n",
    "    output.append([batch_idx, torch.argmax(model(data)).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission = pd.DataFrame(output, columns=['Id','Class'])\n",
    "Submission.to_csv('kaggle.out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
